<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>microservices on // Álex Go{,5z}</title><link>https://agonzalezro.github.io/tags/microservices/</link><description>Recent content in microservices on // Álex Go{,5z}</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 17 Dec 2015 00:00:00 +0000</lastBuildDate><atom:link href="https://agonzalezro.github.io/tags/microservices/index.xml" rel="self" type="application/rss+xml"/><item><title>Using Kong with Kubernetes</title><link>https://agonzalezro.github.io/posts/kong-k8s/</link><pubDate>Thu, 17 Dec 2015 00:00:00 +0000</pubDate><guid>https://agonzalezro.github.io/posts/kong-k8s/</guid><description>
&lt;blockquote>
&lt;p>This was originally posted on &lt;a href="http://k8s.uk/using-kong-with-kubernetes.html">k8s.uk&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>If you don&amp;rsquo;t know about &lt;a href="https://getkong.org">Kong&lt;/a> yet, you should take a look. It&amp;rsquo;s an Open Source API Gateway, they define themselves as: &amp;ldquo;The open-source management layer for APIs, delivering high performance and reliability.&amp;rdquo; and they are quite right.&lt;/p>
&lt;p>I was playing with Kong lately at work (&lt;a href="http://jobandtalent.com">jobandtalent.com&lt;/a>, we are hiring!) and I think that it could be pretty awesome as a entry layer to your microservices platform running in Kubernetes.&lt;/p>
&lt;p>For the sake of simplicity I will not run Kong in Kubernetes, but it shouldn&amp;rsquo;t be so difficult since &lt;a href="https://getkong.org/install/">they already provide Docker images&lt;/a>. Also, running Kong on the same cluster you will be able to use internal networking between pods: win-win.&lt;/p>
&lt;p>So, what will I show?&lt;/p>
&lt;ul>
&lt;li>I will deploy a Kubernetes with 2 pods (our 2 microservices) &amp;amp;&lt;/li>
&lt;li>I will install Kong locally and configure it to point to this 2 services.&lt;/li>
&lt;/ul>
&lt;h2 id="go--packing">Go &amp;amp; packing&lt;/h2>
&lt;p>I&amp;rsquo;ve created a small Go app that will show the value of an environment variable when you &lt;code>GET /&lt;/code>:&lt;/p>
&lt;pre>&lt;code>package main
import (
&amp;quot;fmt&amp;quot;
&amp;quot;log&amp;quot;
&amp;quot;net/http&amp;quot;
&amp;quot;os&amp;quot;
)
func main() {
http.HandleFunc(&amp;quot;/&amp;quot;, func(w http.ResponseWriter, r *http.Request) {
fmt.Fprintf(w, os.Getenv(&amp;quot;TEST_RESULT&amp;quot;))
})
log.Fatal(http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil))
}
&lt;/code>&lt;/pre>
&lt;p>Now we will build the application to later pack it in our image. Remember that if you are in Mac you will need to cross-compile the app to work on Linux:&lt;/p>
&lt;pre>&lt;code>$ GOOS=linux go build
&lt;/code>&lt;/pre>
&lt;p>We can pack it into our images now. For doing so we need a &lt;code>Dockerfile&lt;/code>. It&amp;rsquo;s a simple binary, so the &lt;code>Dockerfile&lt;/code> is not complex at all:&lt;/p>
&lt;pre>&lt;code>FROM scratch
ADD app /
ENTRYPOINT [&amp;quot;/app&amp;quot;]
&lt;/code>&lt;/pre>
&lt;p>Cool! What can we do now with our shiny image? Yes, you are right! Push it to the hub:&lt;/p>
&lt;pre>&lt;code>$ docker build -t agonzalezro/kong-test .
$ docker push agonzalezro/kong-test
&lt;/code>&lt;/pre>
&lt;h2 id="k8s">k8s&lt;/h2>
&lt;p>We have our image on the registry and all we need now is running it on Kubernetes. I am using &lt;a href="https://cloud.google.com/container-engine/">Google Container Engine&lt;/a> for deploying this, but you can use whatever you prefer.&lt;/p>
&lt;p>Let&amp;rsquo;s create our RCs &amp;amp; services:&lt;/p>
&lt;pre>&lt;code># rc1.yml
apiVersion: v1
kind: ReplicationController
metadata:
name: api1
spec:
selector:
name: api
version: first
template:
metadata:
labels:
name: api
version: first
spec:
containers:
- name: app
image: agonzalezro/kong-test
env:
- name: TEST_RESULT
value: &amp;quot;This is the first app&amp;quot;
# rc2.yml
apiVersion: v1
kind: ReplicationController
metadata:
name: api2
spec:
selector:
name: api
version: second
template:
metadata:
labels:
name: api
version: second
spec:
containers:
- name: app
image: agonzalezro/kong-test
env:
- name: TEST_RESULT
value: &amp;quot;Second!&amp;quot;
# svc1.yml
apiVersion: v1
kind: Service
metadata:
name: app1-svc
spec:
type: LoadBalancer
ports:
- port: 80
targetPort: 8080
selector:
name: api
version: first
# svc2.yml
apiVersion: v1
kind: Service
metadata:
name: app2-svc
spec:
type: LoadBalancer
ports:
- port: 80
targetPort: 8080
selector:
name: api
version: second
&lt;/code>&lt;/pre>
&lt;p>And now run it:&lt;/p>
&lt;pre>&lt;code>$ kubectl create -f rc1.yml -f rc2.yml -f svc1.yml -f svc2.yml
&lt;/code>&lt;/pre>
&lt;p>Wait for the service and the pods to be ready and check their IPS:&lt;/p>
&lt;pre>&lt;code>$ kubectl get services
NAME CLUSTER_IP EXTERNAL_IP PORT(S) SELECTOR AGE
app1-svc 10.159.242.86 130.211.89.175 80/TCP name=api,version=first 17m
app2-svc 10.159.246.93 104.155.53.175 80/TCP name=api,version=second 17m
kubernetes 10.159.240.1 &amp;lt;none&amp;gt; 443/TCP &amp;lt;none&amp;gt; 1h
&lt;/code>&lt;/pre>
&lt;h2 id="kong">Kong&lt;/h2>
&lt;p>Follow the instruction here: &lt;a href="https://getkong.org/install/docker/">https://getkong.org/install/docker/&lt;/a> to install Kong locally.&lt;/p>
&lt;p>Yeah! We have it up &amp;amp; running so let&amp;rsquo;s point it to our shinny cluster. We need to use Kong API for that (port &lt;code>:8001&lt;/code>):&lt;/p>
&lt;pre>&lt;code>$ http http://dockerhost:8001/apis/ name=first upstream_url=http://130.211.89.175 request_path=/first strip_request_path=true
$ http http://dockerhost:8001/apis/ name=second upstream_url=http://104.155.53.175 request_path=/second strip_request_path=true
&lt;/code>&lt;/pre>
&lt;p>What we did here? We set up two new endpoints &lt;code>/first&lt;/code> &amp;amp; &lt;code>/second&lt;/code> that are pointing to the both Kubernetes services previously created. We could have done it with DNS as well using &lt;code>request_host&lt;/code> instead.&lt;/p>
&lt;p>Lets call Kong on the port &lt;code>:8000&lt;/code> to use them:&lt;/p>
&lt;pre>&lt;code>$ http http://dockerhost:8000/first
HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 21
Content-Type: text/plain; charset=utf-8
Date: Thu, 17 Dec 2015 21:43:41 GMT
Via: kong/0.5.4
This is the first app
$ http http://dockerhost:8000/second
HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 7
Content-Type: text/plain; charset=utf-8
Date: Thu, 17 Dec 2015 21:43:44 GMT
Via: kong/0.5.4
Second!
&lt;/code>&lt;/pre>
&lt;p>\o/ We did it!&lt;/p>
&lt;h2 id="next-steps">Next steps&lt;/h2>
&lt;p>You have Kong pointed to your cluster, now it&amp;rsquo;s up to your imagination what to do next. I would say try to configure some rate limiting or auth, it&amp;rsquo;s deadly simply. Check them here: &lt;a href="https://getkong.org/plugins/">https://getkong.org/plugins/&lt;/a>&lt;/p>
&lt;p>If you have any question or you want to discuss this further let me know at &lt;a href="https://twitter.com/agonzalezro">@agonzalezro&lt;/a>.&lt;/p></description></item></channel></rss>